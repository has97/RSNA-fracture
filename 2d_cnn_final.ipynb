{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5d69ff01",
   "metadata": {
    "papermill": {
     "duration": 0.010342,
     "end_time": "2022-11-22T08:56:32.449767",
     "exception": false,
     "start_time": "2022-11-22T08:56:32.439425",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Downloading Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "21b9e50b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-22T08:56:32.471782Z",
     "iopub.status.busy": "2022-11-22T08:56:32.470484Z",
     "iopub.status.idle": "2022-11-22T08:57:28.962319Z",
     "shell.execute_reply": "2022-11-22T08:57:28.960265Z"
    },
    "papermill": {
     "duration": 56.507103,
     "end_time": "2022-11-22T08:57:28.966291",
     "exception": false,
     "start_time": "2022-11-22T08:56:32.459188",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting python-gdcm\r\n",
      "  Downloading python_gdcm-3.0.20-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (13.0 MB)\r\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.0/13.0 MB\u001b[0m \u001b[31m14.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hInstalling collected packages: python-gdcm\r\n",
      "Successfully installed python-gdcm-3.0.20\r\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\r\n",
      "\u001b[0mCollecting pylibjpeg[all]\r\n",
      "  Downloading pylibjpeg-1.4.0-py3-none-any.whl (28 kB)\r\n",
      "Requirement already satisfied: numpy in /opt/conda/lib/python3.7/site-packages (from pylibjpeg[all]) (1.21.6)\r\n",
      "Collecting pylibjpeg-openjpeg\r\n",
      "  Downloading pylibjpeg_openjpeg-1.2.1-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\r\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m1.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hCollecting pylibjpeg-libjpeg\r\n",
      "  Downloading pylibjpeg_libjpeg-1.3.2-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (4.3 MB)\r\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.3/4.3 MB\u001b[0m \u001b[31m9.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hCollecting pylibjpeg-rle\r\n",
      "  Downloading pylibjpeg_rle-1.3.0-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (969 kB)\r\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m969.3/969.3 kB\u001b[0m \u001b[31m31.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hInstalling collected packages: pylibjpeg-rle, pylibjpeg-openjpeg, pylibjpeg-libjpeg, pylibjpeg\r\n",
      "Successfully installed pylibjpeg-1.4.0 pylibjpeg-libjpeg-1.3.2 pylibjpeg-openjpeg-1.2.1 pylibjpeg-rle-1.3.0\r\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\r\n",
      "\u001b[0mCollecting timm\r\n",
      "  Downloading timm-0.6.11-py3-none-any.whl (548 kB)\r\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m548.7/548.7 kB\u001b[0m \u001b[31m697.9 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hRequirement already satisfied: torchvision in /opt/conda/lib/python3.7/site-packages (from timm) (0.12.0)\r\n",
      "Requirement already satisfied: huggingface-hub in /opt/conda/lib/python3.7/site-packages (from timm) (0.10.1)\r\n",
      "Requirement already satisfied: pyyaml in /opt/conda/lib/python3.7/site-packages (from timm) (6.0)\r\n",
      "Requirement already satisfied: torch>=1.7 in /opt/conda/lib/python3.7/site-packages (from timm) (1.11.0)\r\n",
      "Requirement already satisfied: typing-extensions in /opt/conda/lib/python3.7/site-packages (from torch>=1.7->timm) (4.1.1)\r\n",
      "Requirement already satisfied: packaging>=20.9 in /opt/conda/lib/python3.7/site-packages (from huggingface-hub->timm) (21.3)\r\n",
      "Requirement already satisfied: filelock in /opt/conda/lib/python3.7/site-packages (from huggingface-hub->timm) (3.7.1)\r\n",
      "Requirement already satisfied: requests in /opt/conda/lib/python3.7/site-packages (from huggingface-hub->timm) (2.28.1)\r\n",
      "Requirement already satisfied: tqdm in /opt/conda/lib/python3.7/site-packages (from huggingface-hub->timm) (4.64.0)\r\n",
      "Requirement already satisfied: importlib-metadata in /opt/conda/lib/python3.7/site-packages (from huggingface-hub->timm) (4.13.0)\r\n",
      "Requirement already satisfied: numpy in /opt/conda/lib/python3.7/site-packages (from torchvision->timm) (1.21.6)\r\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /opt/conda/lib/python3.7/site-packages (from torchvision->timm) (9.1.1)\r\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.7/site-packages (from packaging>=20.9->huggingface-hub->timm) (3.0.9)\r\n",
      "Requirement already satisfied: zipp>=0.5 in /opt/conda/lib/python3.7/site-packages (from importlib-metadata->huggingface-hub->timm) (3.8.0)\r\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.7/site-packages (from requests->huggingface-hub->timm) (3.3)\r\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.7/site-packages (from requests->huggingface-hub->timm) (2022.9.24)\r\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in /opt/conda/lib/python3.7/site-packages (from requests->huggingface-hub->timm) (2.1.0)\r\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /opt/conda/lib/python3.7/site-packages (from requests->huggingface-hub->timm) (1.26.12)\r\n",
      "Installing collected packages: timm\r\n",
      "Successfully installed timm-0.6.11\r\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\r\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!pip install python-gdcm\n",
    "!pip install -U pylibjpeg[all]\n",
    "!pip install timm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d23920a",
   "metadata": {
    "papermill": {
     "duration": 0.017191,
     "end_time": "2022-11-22T08:57:29.000507",
     "exception": false,
     "start_time": "2022-11-22T08:57:28.983316",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Importing and Installing Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3d04aa78",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-22T08:57:29.038281Z",
     "iopub.status.busy": "2022-11-22T08:57:29.037142Z",
     "iopub.status.idle": "2022-11-22T08:57:37.579287Z",
     "shell.execute_reply": "2022-11-22T08:57:37.577554Z"
    },
    "papermill": {
     "duration": 8.564792,
     "end_time": "2022-11-22T08:57:37.582690",
     "exception": false,
     "start_time": "2022-11-22T08:57:29.017898",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "import os\n",
    "import gc\n",
    "import matplotlib.pyplot as plt\n",
    "import pydicom\n",
    "from pydicom.pixel_data_handlers.util import apply_voi_lut\n",
    "import pathlib\n",
    "import random\n",
    "import timm\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch import optim\n",
    "import albumentations as A\n",
    "from albumentations.pytorch import ToTensorV2\n",
    "import albumentations.pytorch\n",
    "\n",
    "from fastai.vision.all import *\n",
    "from fastai.data.core import *\n",
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "# Setting Seed for reproducibility\n",
    "seed = 42\n",
    "random.seed(seed)\n",
    "torch.manual_seed(seed)  \n",
    "torch.cuda.manual_seed(seed)  \n",
    "torch.cuda.manual_seed_all(seed)  \n",
    "torch.backends.cudnn.deterministic = True\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfbaeedf",
   "metadata": {
    "papermill": {
     "duration": 0.015518,
     "end_time": "2022-11-22T08:57:37.614479",
     "exception": false,
     "start_time": "2022-11-22T08:57:37.598961",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Hyperparamters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "71300c44",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-22T08:57:37.648264Z",
     "iopub.status.busy": "2022-11-22T08:57:37.647526Z",
     "iopub.status.idle": "2022-11-22T08:57:37.653681Z",
     "shell.execute_reply": "2022-11-22T08:57:37.652273Z"
    },
    "papermill": {
     "duration": 0.026352,
     "end_time": "2022-11-22T08:57:37.656493",
     "exception": false,
     "start_time": "2022-11-22T08:57:37.630141",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# timm.list_models()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "68ad0be8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-22T08:57:37.690463Z",
     "iopub.status.busy": "2022-11-22T08:57:37.689267Z",
     "iopub.status.idle": "2022-11-22T08:57:37.700011Z",
     "shell.execute_reply": "2022-11-22T08:57:37.698550Z"
    },
    "papermill": {
     "duration": 0.030906,
     "end_time": "2022-11-22T08:57:37.702881",
     "exception": false,
     "start_time": "2022-11-22T08:57:37.671975",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "model_name = 'resnet50' # Change the model here to resnet 50 or efficient net\n",
    "epochs = 6\n",
    "batch_size = 8\n",
    "number_of_slices = 160 # Mean of, mean and median of no of slices\n",
    "input_shape = (224, 224)\n",
    "resize_size = 256\n",
    "num_of_hidden = 2\n",
    "hidden_dimension = [256, 64]\n",
    "output_categories = 8\n",
    "loss_weights = {'-ve': torch.tensor([1., 1., 1., 1., 1., 1., 1., 7.]),\n",
    "                '+ve': torch.tensor([2., 2., 2., 2., 2., 2., 2., 14.])}\n",
    "criterion = nn.BCEWithLogitsLoss(reduction = 'none')\n",
    "train_size = 0.8\n",
    "val_size = 0.2\n",
    "lr_freeze = 0.0001\n",
    "lr_unfreeze = slice(3e-07, 3e-06)\n",
    "save_path = '/kaggle/working/'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86d36a1f",
   "metadata": {
    "papermill": {
     "duration": 0.015604,
     "end_time": "2022-11-22T08:57:37.734082",
     "exception": false,
     "start_time": "2022-11-22T08:57:37.718478",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Helper Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f78e9c19",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-22T08:57:37.772015Z",
     "iopub.status.busy": "2022-11-22T08:57:37.770203Z",
     "iopub.status.idle": "2022-11-22T08:57:37.784476Z",
     "shell.execute_reply": "2022-11-22T08:57:37.782954Z"
    },
    "papermill": {
     "duration": 0.036596,
     "end_time": "2022-11-22T08:57:37.787817",
     "exception": false,
     "start_time": "2022-11-22T08:57:37.751221",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def loss(y_true, y_pred):\n",
    "    losses = nn.BCEWithLogitsLoss()\n",
    "    loss = losses(y_true,y_pred)\n",
    "    weights  = y_true*loss_weights['+ve'].to(device) + (1-y_true)*loss_weights['-ve'].to(device)\n",
    "    loss = (loss * weights).sum(axis=1)\n",
    "    loss = loss.mean()\n",
    "    loss = (loss / weights.sum(axis=1)).sum()\n",
    "    return loss\n",
    "\n",
    "def metric(y_true, y_pred):\n",
    "    losses = nn.BCEWithLogitsLoss()\n",
    "    loss = losses(y_true,y_pred)\n",
    "    weights  = y_true*loss_weights['+ve'].to(device) + (1-y_true)*loss_weights['-ve'].to(device)\n",
    "    loss = (loss * weights).sum(axis=1)\n",
    "    loss = loss.mean()\n",
    "    loss = (loss / weights.sum(axis=1)).sum()\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6411ae61",
   "metadata": {
    "papermill": {
     "duration": 0.016383,
     "end_time": "2022-11-22T08:57:37.820241",
     "exception": false,
     "start_time": "2022-11-22T08:57:37.803858",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Loading Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2da940e4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-22T08:57:37.857085Z",
     "iopub.status.busy": "2022-11-22T08:57:37.856566Z",
     "iopub.status.idle": "2022-11-22T08:57:37.906136Z",
     "shell.execute_reply": "2022-11-22T08:57:37.904419Z"
    },
    "papermill": {
     "duration": 0.073514,
     "end_time": "2022-11-22T08:57:37.911119",
     "exception": false,
     "start_time": "2022-11-22T08:57:37.837605",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>StudyInstanceUID</th>\n",
       "      <th>patient_overall</th>\n",
       "      <th>C1</th>\n",
       "      <th>C2</th>\n",
       "      <th>C3</th>\n",
       "      <th>C4</th>\n",
       "      <th>C5</th>\n",
       "      <th>C6</th>\n",
       "      <th>C7</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.2.826.0.1.3680043.6200</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.2.826.0.1.3680043.27262</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.2.826.0.1.3680043.21561</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.2.826.0.1.3680043.12351</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.2.826.0.1.3680043.1363</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            StudyInstanceUID  patient_overall  C1  C2  C3  C4  C5  C6  C7\n",
       "0   1.2.826.0.1.3680043.6200                1   1   1   0   0   0   0   0\n",
       "1  1.2.826.0.1.3680043.27262                1   0   1   0   0   0   0   0\n",
       "2  1.2.826.0.1.3680043.21561                1   0   1   0   0   0   0   0\n",
       "3  1.2.826.0.1.3680043.12351                0   0   0   0   0   0   0   0\n",
       "4   1.2.826.0.1.3680043.1363                1   0   0   0   0   1   0   0"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "base_path = pathlib.Path('/kaggle/input/rsna-2022-cervical-spine-fracture-detection')\n",
    "df = pd.read_csv(base_path/'train.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e1e00789",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-22T08:57:37.947032Z",
     "iopub.status.busy": "2022-11-22T08:57:37.946544Z",
     "iopub.status.idle": "2022-11-22T08:57:37.965582Z",
     "shell.execute_reply": "2022-11-22T08:57:37.963503Z"
    },
    "papermill": {
     "duration": 0.040448,
     "end_time": "2022-11-22T08:57:37.969228",
     "exception": false,
     "start_time": "2022-11-22T08:57:37.928780",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2018\n"
     ]
    }
   ],
   "source": [
    "df = df[df['StudyInstanceUID'] != '1.2.826.0.1.3680043.20574'].copy()\n",
    "print(len(df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "23fd2885",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-22T08:57:38.005024Z",
     "iopub.status.busy": "2022-11-22T08:57:38.003876Z",
     "iopub.status.idle": "2022-11-22T08:57:38.050121Z",
     "shell.execute_reply": "2022-11-22T08:57:38.048317Z"
    },
    "papermill": {
     "duration": 0.069899,
     "end_time": "2022-11-22T08:57:38.055382",
     "exception": false,
     "start_time": "2022-11-22T08:57:37.985483",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>StudyInstanceUID</th>\n",
       "      <th>patient_overall</th>\n",
       "      <th>C1</th>\n",
       "      <th>C2</th>\n",
       "      <th>C3</th>\n",
       "      <th>C4</th>\n",
       "      <th>C5</th>\n",
       "      <th>C6</th>\n",
       "      <th>C7</th>\n",
       "      <th>path</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.2.826.0.1.3680043.6200</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>/kaggle/input/rsna-2022-cervical-spine-fracture-detection/train_images/1.2.826.0.1.3680043.6200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.2.826.0.1.3680043.27262</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>/kaggle/input/rsna-2022-cervical-spine-fracture-detection/train_images/1.2.826.0.1.3680043.27262</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.2.826.0.1.3680043.21561</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>/kaggle/input/rsna-2022-cervical-spine-fracture-detection/train_images/1.2.826.0.1.3680043.21561</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.2.826.0.1.3680043.12351</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>/kaggle/input/rsna-2022-cervical-spine-fracture-detection/train_images/1.2.826.0.1.3680043.12351</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.2.826.0.1.3680043.1363</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>/kaggle/input/rsna-2022-cervical-spine-fracture-detection/train_images/1.2.826.0.1.3680043.1363</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            StudyInstanceUID  patient_overall  C1  C2  C3  C4  C5  C6  C7  \\\n",
       "0   1.2.826.0.1.3680043.6200                1   1   1   0   0   0   0   0   \n",
       "1  1.2.826.0.1.3680043.27262                1   0   1   0   0   0   0   0   \n",
       "2  1.2.826.0.1.3680043.21561                1   0   1   0   0   0   0   0   \n",
       "3  1.2.826.0.1.3680043.12351                0   0   0   0   0   0   0   0   \n",
       "4   1.2.826.0.1.3680043.1363                1   0   0   0   0   1   0   0   \n",
       "\n",
       "                                                                                               path  \n",
       "0   /kaggle/input/rsna-2022-cervical-spine-fracture-detection/train_images/1.2.826.0.1.3680043.6200  \n",
       "1  /kaggle/input/rsna-2022-cervical-spine-fracture-detection/train_images/1.2.826.0.1.3680043.27262  \n",
       "2  /kaggle/input/rsna-2022-cervical-spine-fracture-detection/train_images/1.2.826.0.1.3680043.21561  \n",
       "3  /kaggle/input/rsna-2022-cervical-spine-fracture-detection/train_images/1.2.826.0.1.3680043.12351  \n",
       "4   /kaggle/input/rsna-2022-cervical-spine-fracture-detection/train_images/1.2.826.0.1.3680043.1363  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['path'] = list(map(lambda x: base_path/'train_images'/x, df['StudyInstanceUID']))\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b933c6c8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-22T08:57:38.091112Z",
     "iopub.status.busy": "2022-11-22T08:57:38.089830Z",
     "iopub.status.idle": "2022-11-22T08:57:38.097808Z",
     "shell.execute_reply": "2022-11-22T08:57:38.096444Z"
    },
    "papermill": {
     "duration": 0.029153,
     "end_time": "2022-11-22T08:57:38.100835",
     "exception": false,
     "start_time": "2022-11-22T08:57:38.071682",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# min_slices = 1500\n",
    "# max_slices = 0\n",
    "# mean_slices = 0\n",
    "# count = 0\n",
    "# slices_val = []\n",
    "# for i in df['path']:\n",
    "#     no_of_images = len(list(i.glob(\"*\")))\n",
    "#     count+=1\n",
    "#     slices_val.append(no_of_images)\n",
    "#     mean_slices += no_of_images\n",
    "#     if min_slices > no_of_images:\n",
    "#         min_slices = no_of_images\n",
    "#     if no_of_images > max_slices:\n",
    "#         max_slices = no_of_images\n",
    "# print(\"Minimum Slices in an Image\", min_slices)\n",
    "# print(\"Maximum Slices in an Image\", max_slices)\n",
    "# print(\"Mean Slices in an Image\", mean_slices / count)\n",
    "# slices_val.sort()\n",
    "# print(\"Median Slices in an Image\", slices_val[(count + 1)//2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2fb268d7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-22T08:57:38.136599Z",
     "iopub.status.busy": "2022-11-22T08:57:38.135777Z",
     "iopub.status.idle": "2022-11-22T08:57:38.151627Z",
     "shell.execute_reply": "2022-11-22T08:57:38.150214Z"
    },
    "papermill": {
     "duration": 0.037874,
     "end_time": "2022-11-22T08:57:38.155222",
     "exception": false,
     "start_time": "2022-11-22T08:57:38.117348",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "strat = StratifiedShuffleSplit(n_splits=2, test_size = val_size/(train_size + val_size), \n",
    "                                random_state=seed)\n",
    "for (train_idx, valid_idx) in strat.split(df.index, df['C3']):\n",
    "    valid_data = df.iloc[valid_idx]\n",
    "    train_data = df.iloc[train_idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6065a7eb",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-22T08:57:38.192976Z",
     "iopub.status.busy": "2022-11-22T08:57:38.192111Z",
     "iopub.status.idle": "2022-11-22T08:57:38.201352Z",
     "shell.execute_reply": "2022-11-22T08:57:38.199877Z"
    },
    "papermill": {
     "duration": 0.030863,
     "end_time": "2022-11-22T08:57:38.204471",
     "exception": false,
     "start_time": "2022-11-22T08:57:38.173608",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1614, 404)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_data), len(valid_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "bec08805",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-22T08:57:38.241232Z",
     "iopub.status.busy": "2022-11-22T08:57:38.240003Z",
     "iopub.status.idle": "2022-11-22T08:57:38.257167Z",
     "shell.execute_reply": "2022-11-22T08:57:38.255541Z"
    },
    "papermill": {
     "duration": 0.039398,
     "end_time": "2022-11-22T08:57:38.260721",
     "exception": false,
     "start_time": "2022-11-22T08:57:38.221323",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    0.521066\n",
       "1    0.478934\n",
       "Name: patient_overall, dtype: float64"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data['patient_overall'].value_counts(normalize = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e58cab22",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-22T08:57:38.296634Z",
     "iopub.status.busy": "2022-11-22T08:57:38.296185Z",
     "iopub.status.idle": "2022-11-22T08:57:38.307658Z",
     "shell.execute_reply": "2022-11-22T08:57:38.306180Z"
    },
    "papermill": {
     "duration": 0.032903,
     "end_time": "2022-11-22T08:57:38.310917",
     "exception": false,
     "start_time": "2022-11-22T08:57:38.278014",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    0.537129\n",
       "1    0.462871\n",
       "Name: patient_overall, dtype: float64"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "valid_data['patient_overall'].value_counts(normalize = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "710957ab",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-22T08:57:38.349300Z",
     "iopub.status.busy": "2022-11-22T08:57:38.347926Z",
     "iopub.status.idle": "2022-11-22T08:57:38.371295Z",
     "shell.execute_reply": "2022-11-22T08:57:38.370008Z"
    },
    "papermill": {
     "duration": 0.045421,
     "end_time": "2022-11-22T08:57:38.374558",
     "exception": false,
     "start_time": "2022-11-22T08:57:38.329137",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class CervicalDataset(Dataset):\n",
    "    def __init__(self, df, no_of_slice, prob = 0.5, test = False, tta = False):\n",
    "        '''\n",
    "        '''\n",
    "        self.df = df\n",
    "        self.test = test\n",
    "        self.tta = tta\n",
    "        self.prob = prob\n",
    "        self.no_of_slice = no_of_slice\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        data = self.df['path'].iloc[idx]\n",
    "        images_path = list(data.glob(\"*\"))\n",
    "        no_of_images = len(images_path)\n",
    "        transforms_list = [A.LongestMaxSize(max_size=resize_size, interpolation=1),\n",
    "                           A.PadIfNeeded(min_height=input_shape[0], min_width=input_shape[1],\n",
    "                                         border_mode=0, value=(0,0,0))]\n",
    "        if not(self.test):\n",
    "            value = np.random.uniform()\n",
    "            if value >= self.prob: \n",
    "                transforms_list.append(A.HorizontalFlip(always_apply = True))\n",
    "                \n",
    "            value = np.random.uniform()\n",
    "            if value >= self.prob:\n",
    "                transforms_list.append(A.ShiftScaleRotate(shift_limit = 0.15,\n",
    "                                                          border_mode = 2, always_apply = True))\n",
    "            \n",
    "            # Other Transformation to add: Random Brightness, Contrast, Clahe, Scale Intensity \n",
    "                \n",
    "            transforms_list.append(A.CenterCrop(height = input_shape[0], width = input_shape[1]))\n",
    "            transforms = A.Compose(transforms_list)\n",
    "        elif self.test and self.tta:\n",
    "            pass\n",
    "        if self.test:\n",
    "            transforms_list.append(A.CenterCrop(height = input_shape[0], width = input_shape[1]))\n",
    "            transforms = A.Compose(transforms_list)\n",
    "            \n",
    "        imgs = []\n",
    "        for i in range(1, len(images_path)+1):\n",
    "            path = images_path[0].parent/f\"{i}.dcm\"\n",
    "            \n",
    "            try:\n",
    "                data = pydicom.dcmread(path)\n",
    "#                 data.PhotometricInterpretation = 'YBR_FULL'\n",
    "                img_data = apply_voi_lut(data.pixel_array, data)\n",
    "                img_data = img_data - np.min(img_data)\n",
    "                if np.max(img_data) != 0:\n",
    "                    img_data = img_data / np.max(img_data)\n",
    "    #             data = (data * 255).astype(np.uint8)\n",
    "                album = transforms(image = img_data)\n",
    "                img_data = album['image']\n",
    "            except FileNotFoundError:\n",
    "                continue\n",
    "            imgs.append(img_data)\n",
    "            if len(imgs) > self.no_of_slice:\n",
    "                break\n",
    "            \n",
    "        if len(imgs) > self.no_of_slice:\n",
    "            imgs = imgs[:self.no_of_slice]\n",
    "        \n",
    "        if len(imgs) < self.no_of_slice:\n",
    "            imgs.extend([np.zeros((input_shape[0], input_shape[1]))\n",
    "                         for i in range(self.no_of_slice - len(imgs))])\n",
    "\n",
    "        imgs = np.array(imgs)\n",
    "        imgs = torch.from_numpy(imgs).float()\n",
    "        labels = torch.as_tensor(self.df.iloc[idx].iloc[1:-1]).float()\n",
    "        return imgs, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8497ff27",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-22T08:57:38.411092Z",
     "iopub.status.busy": "2022-11-22T08:57:38.409839Z",
     "iopub.status.idle": "2022-11-22T08:57:38.417706Z",
     "shell.execute_reply": "2022-11-22T08:57:38.416165Z"
    },
    "papermill": {
     "duration": 0.029781,
     "end_time": "2022-11-22T08:57:38.421146",
     "exception": false,
     "start_time": "2022-11-22T08:57:38.391365",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_data(batch_size):\n",
    "    train_dataset = CervicalDataset(train_data, no_of_slice = number_of_slices)\n",
    "    valid_dataset = CervicalDataset(valid_data, no_of_slice = number_of_slices, test = True)\n",
    "    dls = DataLoaders.from_dsets(train_dataset, valid_dataset, bs = batch_size)\n",
    "    return dls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "531ee4e7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-22T08:57:38.457609Z",
     "iopub.status.busy": "2022-11-22T08:57:38.456608Z",
     "iopub.status.idle": "2022-11-22T08:57:38.462539Z",
     "shell.execute_reply": "2022-11-22T08:57:38.461319Z"
    },
    "papermill": {
     "duration": 0.027266,
     "end_time": "2022-11-22T08:57:38.465442",
     "exception": false,
     "start_time": "2022-11-22T08:57:38.438176",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# train_dataset = CervicalDataset(train_data, no_of_slice = number_of_slices)\n",
    "# trainloader = DataLoader(train_dataset, batch_size = 16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "5fdc0029",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-22T08:57:38.502142Z",
     "iopub.status.busy": "2022-11-22T08:57:38.500919Z",
     "iopub.status.idle": "2022-11-22T08:57:38.506603Z",
     "shell.execute_reply": "2022-11-22T08:57:38.505173Z"
    },
    "papermill": {
     "duration": 0.027344,
     "end_time": "2022-11-22T08:57:38.509854",
     "exception": false,
     "start_time": "2022-11-22T08:57:38.482510",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# imgs, lbls = next(iter(trainloader))\n",
    "# print(imgs.shape, lbls.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "26dd5d60",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-22T08:57:38.546883Z",
     "iopub.status.busy": "2022-11-22T08:57:38.545679Z",
     "iopub.status.idle": "2022-11-22T08:57:38.552352Z",
     "shell.execute_reply": "2022-11-22T08:57:38.550923Z"
    },
    "papermill": {
     "duration": 0.028132,
     "end_time": "2022-11-22T08:57:38.555383",
     "exception": false,
     "start_time": "2022-11-22T08:57:38.527251",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# # Visualize\n",
    "# image = imgs[3]\n",
    "# print(image.shape) # No_of_slice x height x width\n",
    "# fig, axes = plt.subplots(nrows = 1, ncols = 4, figsize = (15,10))\n",
    "# axes[0].imshow(image.numpy().mean(axis = 0), cmap = 'gray')\n",
    "# axes[0].axis('off')\n",
    "# axes[1].imshow(image.numpy()[:, :, image.shape[2]//2], cmap = 'gray')\n",
    "# axes[1].axis('off')\n",
    "# axes[2].imshow(image.numpy()[:, 128, :], cmap = 'gray')\n",
    "# axes[2].axis('off')\n",
    "# axes[3].imshow(image.numpy()[6, :, :], cmap = 'gray')\n",
    "# axes[3].axis('off');"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f19ddfb6",
   "metadata": {
    "papermill": {
     "duration": 0.016465,
     "end_time": "2022-11-22T08:57:38.589297",
     "exception": false,
     "start_time": "2022-11-22T08:57:38.572832",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Model Building"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "1bab21c5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-22T08:57:38.625820Z",
     "iopub.status.busy": "2022-11-22T08:57:38.625385Z",
     "iopub.status.idle": "2022-11-22T08:57:38.648797Z",
     "shell.execute_reply": "2022-11-22T08:57:38.647487Z"
    },
    "papermill": {
     "duration": 0.045368,
     "end_time": "2022-11-22T08:57:38.651678",
     "exception": false,
     "start_time": "2022-11-22T08:57:38.606310",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# If using Efficient net use base.classifier instead of base.fc otherwise make no changes\n",
    "class Identity(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Identity, self).__init__()\n",
    "        \n",
    "    def forward(self, x):\n",
    "        return x\n",
    "        \n",
    "\n",
    "class Network(nn.Module):\n",
    "    def __init__(self, base, input_channels, number_of_hidden, hidden, output_categories, freeze_layer):\n",
    "        super(Network, self).__init__()\n",
    "        if (number_of_hidden != len(hidden)):\n",
    "            raise \"Number of Hidden layer and length of hidden dim must be same\"\n",
    "            \n",
    "        \n",
    "        hidden_dim = hidden[:]\n",
    "        hidden_dim.insert(0, base.fc.in_features)\n",
    "        \n",
    "        \n",
    "        self.p = 0.5\n",
    "        \n",
    "        self.cnn_head = nn.Sequential(nn.Conv2d(input_channels, 128, kernel_size = 5, stride = 1, \n",
    "                                                padding = 2, padding_mode = 'reflect'),\n",
    "                                      nn.ReLU(),\n",
    "                                      nn.Conv2d(128, 3, kernel_size = 5, stride = 1,\n",
    "                                                padding = 2,  padding_mode = 'reflect'),\n",
    "                                      nn.ReLU())\n",
    "        base.fc = Identity()\n",
    "        self.network = self.__freeze_layer(base, freeze_layer)\n",
    "        self.classification = self.__fully_connected(number_of_hidden, hidden_dim, output_categories)\n",
    "        self.__initialise_weights()\n",
    "\n",
    "    def __initialise_weights(self):\n",
    "        for m in self.classification:\n",
    "            if isinstance(m, nn.Linear):\n",
    "                nn.init.kaiming_normal_(m.weight)\n",
    "              \n",
    "                if m.bias is not None:\n",
    "                    nn.init.constant_(m.bias, 0)\n",
    "\n",
    "            elif isinstance(m, nn.BatchNorm1d):\n",
    "                nn.init.constant_(m.weight, 1)\n",
    "                nn.init.constant_(m.bias, 0)\n",
    "        \n",
    "        for m in self.cnn_head:\n",
    "            if isinstance(m, nn.Linear):\n",
    "                nn.init.kaiming_normal_(m.weight)\n",
    "              \n",
    "                if m.bias is not None:\n",
    "                    nn.init.constant_(m.bias, 0)\n",
    "\n",
    "            elif isinstance(m, nn.BatchNorm1d):\n",
    "                nn.init.constant_(m.weight, 1)\n",
    "                nn.init.constant_(m.bias, 0)\n",
    "                \n",
    "\n",
    "    def __freeze_layer(self, base, freeze_layer):\n",
    "        cnt = 0\n",
    "        for child in base.children():\n",
    "            cnt+=1\n",
    "            if cnt > freeze_layer:\n",
    "                break\n",
    "\n",
    "            for param in child.parameters():\n",
    "                param.requires_grad = False\n",
    "        return base\n",
    "\n",
    "\n",
    "    def __fully_connected(self, number_of_hidden, hidden_dim, output_categories):\n",
    "        layers = []\n",
    "        layers.append(nn.Dropout(self.p))\n",
    "        for i in range(number_of_hidden):\n",
    "            layers.append(nn.Linear(hidden_dim[i], hidden_dim[i+1]))\n",
    "            layers.append(nn.GELU())\n",
    "            layers.append(nn.BatchNorm1d(hidden_dim[i+1]))\n",
    "            if i != (number_of_hidden-1):\n",
    "                layers.append(nn.Dropout(self.p))\n",
    "\n",
    "        layers.append(nn.Linear(hidden_dim[-1], output_categories))\n",
    "    \n",
    "        return nn.Sequential(*layers)\n",
    "        \n",
    "    def forward(self,x):\n",
    "        x = self.cnn_head(x)\n",
    "        x = self.network(x)\n",
    "        out = self.classification(x)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "6dede4e8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-22T08:57:38.694613Z",
     "iopub.status.busy": "2022-11-22T08:57:38.693736Z",
     "iopub.status.idle": "2022-11-22T08:57:38.705606Z",
     "shell.execute_reply": "2022-11-22T08:57:38.704038Z"
    },
    "papermill": {
     "duration": 0.036145,
     "end_time": "2022-11-22T08:57:38.709363",
     "exception": false,
     "start_time": "2022-11-22T08:57:38.673218",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_learner(model_name, batch_size, unfreeze, metric, save_path):\n",
    "    dls = get_data(batch_size).to(device)\n",
    "    if unfreeze:\n",
    "        network = timm.create_model(model_name, pretrained = True)\n",
    "        model = Network(network, number_of_slices, num_of_hidden, hidden_dimension, output_categories, 0)\n",
    "    else:\n",
    "        network = timm.create_model(model_name, pretrained = True)\n",
    "        model = Network(network, number_of_slices, num_of_hidden, hidden_dimension, output_categories, 8)\n",
    "        \n",
    "    model = model.to(device)\n",
    "    learn = Learner(dls, model, loss_func=loss, metrics=metric, \n",
    "                    model_dir = save_path).to_fp16()\n",
    "    return learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "ae5e9c93",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-22T08:57:38.746221Z",
     "iopub.status.busy": "2022-11-22T08:57:38.745451Z",
     "iopub.status.idle": "2022-11-22T08:57:54.910507Z",
     "shell.execute_reply": "2022-11-22T08:57:54.908883Z"
    },
    "papermill": {
     "duration": 16.187559,
     "end_time": "2022-11-22T08:57:54.914101",
     "exception": false,
     "start_time": "2022-11-22T08:57:38.726542",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading: \"https://github.com/rwightman/pytorch-image-models/releases/download/v0.1-rsb-weights/resnet50_a1_0-14fe96d1.pth\" to /root/.cache/torch/hub/checkpoints/resnet50_a1_0-14fe96d1.pth\n"
     ]
    }
   ],
   "source": [
    "learn = get_learner(model_name, batch_size, True, metric, save_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "6b99e686",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-22T08:57:54.950672Z",
     "iopub.status.busy": "2022-11-22T08:57:54.950221Z",
     "iopub.status.idle": "2022-11-22T08:57:54.955579Z",
     "shell.execute_reply": "2022-11-22T08:57:54.954246Z"
    },
    "papermill": {
     "duration": 0.02698,
     "end_time": "2022-11-22T08:57:54.958400",
     "exception": false,
     "start_time": "2022-11-22T08:57:54.931420",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# learn.lr_find()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "0963193c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-22T08:57:54.995140Z",
     "iopub.status.busy": "2022-11-22T08:57:54.993834Z",
     "iopub.status.idle": "2022-11-22T08:57:56.586600Z",
     "shell.execute_reply": "2022-11-22T08:57:56.584852Z"
    },
    "papermill": {
     "duration": 1.615407,
     "end_time": "2022-11-22T08:57:56.590700",
     "exception": false,
     "start_time": "2022-11-22T08:57:54.975293",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/fastai/learner.py:58: UserWarning: Saved filed doesn't contain an optimizer state.\n",
      "  elif with_opt: warn(\"Saved filed doesn't contain an optimizer state.\")\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<fastai.learner.Learner at 0x7f59804dadd0>"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# saved_file = '/kaggle/input/weights-trained/resnet_50'\n",
    "# learn.load(saved_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "508b8dcb",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-22T08:57:56.680152Z",
     "iopub.status.busy": "2022-11-22T08:57:56.678953Z",
     "iopub.status.idle": "2022-11-22T13:57:04.451780Z",
     "shell.execute_reply": "2022-11-22T13:57:04.450625Z"
    },
    "papermill": {
     "duration": 17947.795233,
     "end_time": "2022-11-22T13:57:04.455450",
     "exception": false,
     "start_time": "2022-11-22T08:57:56.660217",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "    /* Turns off some styling */\n",
       "    progress {\n",
       "        /* gets rid of default border in Firefox and Opera. */\n",
       "        border: none;\n",
       "        /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "        background-size: auto;\n",
       "    }\n",
       "    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n",
       "        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n",
       "    }\n",
       "    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "        background: #F44336;\n",
       "    }\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>metric</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>6.221916</td>\n",
       "      <td>9.412472</td>\n",
       "      <td>9.412472</td>\n",
       "      <td>1:24:07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>6.136239</td>\n",
       "      <td>8.041072</td>\n",
       "      <td>8.041072</td>\n",
       "      <td>1:17:24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>9.317728</td>\n",
       "      <td>7.972219</td>\n",
       "      <td>7.972219</td>\n",
       "      <td>1:16:03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>10.127910</td>\n",
       "      <td>7.430823</td>\n",
       "      <td>7.430823</td>\n",
       "      <td>1:01:30</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Better model found at epoch 0 with metric value: 9.412471771240234.\n",
      "Better model found at epoch 1 with metric value: 8.041071891784668.\n",
      "Better model found at epoch 2 with metric value: 7.9722185134887695.\n",
      "Better model found at epoch 3 with metric value: 7.430822849273682.\n"
     ]
    }
   ],
   "source": [
    "learn.fit_flat_cos(epochs, lr_unfreeze, wd = 0.1,\n",
    "                cbs=[SaveModelCallback(monitor = 'metric', comp = np.less, fname = 'resnet_50_unfreeze')]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8888c59f",
   "metadata": {
    "papermill": {
     "duration": 0.012857,
     "end_time": "2022-11-22T13:57:04.586091",
     "exception": false,
     "start_time": "2022-11-22T13:57:04.573234",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 18049.647711,
   "end_time": "2022-11-22T13:57:08.315582",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2022-11-22T08:56:18.667871",
   "version": "2.3.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
